由于最小的redis集群需要3个主节点，一台机器可运行多个redis实例，我搭建时使用两台机器，6个redis实例，其中三个主节点，三个从节点作为备份
网上很多使用单台服务器开6个端口，操作差不多，只是配置基本相对简单点，多台服务器更接近生产环境
redis 6个节点的ip和端口对应关系
server1:
192.168.1.198:7000
192.168.1.198:7001
192.168.1.198:7002
server2：
192.168.1.199:7003
192.168.1.199:7004
192.168.1.199:7005

1、安装需要的依赖包
[python] view plain copy 在CODE上查看代码片派生到我的代码片
[root@localhost ~]# yum install gcc gcc-c++ kernel-devel automake autoconf libtool make wget tcl vim ruby rubygems unzip git -y

2、两台机器分别下载redis并安装
[python] view plain copy 在CODE上查看代码片派生到我的代码片
[root@localhost src]# cd /usr/local/
[root@localhost local]# wget http://download.redis.io/releases/redis-3.0.6.tar.gz
[root@localhost local]# tar xzf redis-3.0.6.tar.gz
[root@localhost local]# cd redis-3.0.6
[root@localhost redis-3.0.6]# make

3、创建集群需要的目录
server1执行：
[python] view plain copy 在CODE上查看代码片派生到我的代码片
mkdir -p /usr/local/cluster
cd /usr/local/cluster
mkdir 7000
mkdir 7001
mkdir 7002
server2执行：
[python] view plain copy 在CODE上查看代码片派生到我的代码片
mkdir -p /usr/local/cluster
cd /usr/local/cluster
mkdir 7003
mkdir 7004
mkdir 7005

4、修改配置文件redis.conf
cp /usr/local/redis-3.0.6/redis.conf  /usr/local/cluster
cd /usr/local/cluster
vi redis.conf
[python] view plain copy 在CODE上查看代码片派生到我的代码片
##注意每个实例的端口号不同
port 7000
daemonize yes
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 5000
appendonly yes
##修改完redis.conf配置文件中的这些配置项之后把这个配置文件分别拷贝到7000/7001/7002/7003/7004/7005节点目录下
server1执行：
[python] view plain copy 在CODE上查看代码片派生到我的代码片
cp /usr/local/cluster/redis.conf /usr/local/cluster/7000
cp /usr/local/cluster/redis.conf /usr/local/cluster/7001
cp /usr/local/cluster/redis.conf /usr/local/cluster/7002
server2执行：
[python] view plain copy 在CODE上查看代码片派生到我的代码片
cp /usr/local/cluster/redis.conf /usr/local/cluster/7003
cp /usr/local/cluster/redis.conf /usr/local/cluster/7004
cp /usr/local/cluster/redis.conf /usr/local/cluster/7005
##注意：拷贝完成之后要分别修改7001/7002/7003/7004/7005目录下面redis.conf文件中的port参数，分别改为对应的文件夹的名称

5、分别启动这6个redis实例，并查看是否成功：ps -ef|grep redis
server1执行：
[python] view plain copy 在CODE上查看代码片派生到我的代码片
[root@localhost cluster]# cd /usr/local/cluster/7000
[root@localhost 7000]# redis-server redis.conf
[root@localhost 7000]# cd /usr/local/cluster/7001
[root@localhost 7001]# redis-server redis.conf
[root@localhost 7001]# cd /usr/local/cluster/7002
[root@localhost 7002]# redis-server redis.conf
[root@localhost 7002]# ps -ef|grep redis
root      2741     1  0 09:39 ?        00:00:00 redis-server *:7000 [cluster]
root      2747     1  0 09:40 ?        00:00:00 redis-server *:7001 [cluster]
root      2751     1  0 09:40 ?        00:00:00 redis-server *:7002 [cluster]
root      2755  2687  0 09:40 pts/0    00:00:00 grep redis
server2执行：
[python] view plain copy 在CODE上查看代码片派生到我的代码片
[root@localhost cluster]# cd /usr/local/cluster/7003
[root@localhost 7003]# redis-server redis.conf
[root@localhost 7003]# cd /usr/local/cluster/7004
[root@localhost 7004]# redis-server redis.conf
[root@localhost 7004]# cd /usr/local/cluster/7005
[root@localhost 7005]# redis-server redis.conf
[root@localhost 7005]# ps -ef|grep redis
root      1619     1  0 09:40 ?        00:00:00 redis-server *:7003 [cluster]
root      1623     1  0 09:40 ?        00:00:00 redis-server *:7004 [cluster]
root      1627     1  0 09:41 ?        00:00:00 redis-server *:7005 [cluster]
root      1631  1563  0 09:41 pts/0    00:00:00 grep redis

6、执行redis的创建集群命令创建集群（注意ip地址和端口号）
[python] view plain copy 在CODE上查看代码片派生到我的代码片
[root@localhost cluster]# cd /usr/local/redis-3.0.6/src
[root@localhost src]# ./redis-trib.rb  create --replicas 1 192.168.192.145:6479 192.168.192.145:6480 192.168.192.145:6481 192.168.192.145:7479 192.168.192.145:7480 192.168.192.145:7481
6.1到这一步因为前面第1步装了依赖包，未提示ruby和rubygems的错误，但还是会报错，提示不能加载redis，是因为缺少redis和ruby的接口，使用gem 安装
错误内容：
/usr/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require': no such file to load -- redis (LoadError)
        from /usr/lib/ruby/site_ruby/1.8/rubygems/custom_require.rb:31:in `require'
        from ./redis-trib.rb:25
解决：sudo gem install redis
6.2 再次执行第6步的命令，正常执行，提示是否允许修改配置文件，输入yes，然后整个集群配置完成！
[python] view plain copy 在CODE上查看代码片派生到我的代码片
[root@localhost src]# ./redis-trib.rb  create --replicas 1 192.168.192.145:6479 192.168.192.145:6480 192.168.192.145:6481 192.168.192.145:7479 192.168.192.145:7480 192.168.192.145:7481
>>> Creating cluster
>>> Performing hash slots allocation on 6 nodes...
Using 3 masters:
192.168.1.199:7003
192.168.1.198:7000
192.168.1.199:7004
Adding replica 192.168.1.198:7001 to 192.168.1.199:7003
Adding replica 192.168.1.199:7005 to 192.168.1.198:7000
Adding replica 192.168.1.198:7002 to 192.168.1.199:7004
M: 2f70e9f2b4a06a846e46d7034a54e0fe6971beea 192.168.1.198:7000
   slots:5461-10922 (5462 slots) master
S: e60f49920cf8620927b200b0001892d08067d065 192.168.1.198:7001
   replicates 02f1958bd5032caca2fd47a56362c8d562d7e621
S: 26101db06b5c2d4431ca8308cf43d51f6939b4fc 192.168.1.198:7002
   replicates 6c4f18b9e8729c3ab5d43b00b0bc1e2ee976f299
M: 02f1958bd5032caca2fd47a56362c8d562d7e621 192.168.1.199:7003
   slots:0-5460 (5461 slots) master
M: 6c4f18b9e8729c3ab5d43b00b0bc1e2ee976f299 192.168.1.199:7004
   slots:10923-16383 (5461 slots) master
S: ebb27bd0a48b67a4f4e0584be27c1c909944e935 192.168.1.199:7005
   replicates 2f70e9f2b4a06a846e46d7034a54e0fe6971beea
Can I set the above configuration? (type 'yes' to accept): yes
>>> Nodes configuration updated
>>> Assign a different config epoch to each node
>>> Sending CLUSTER MEET messages to join the cluster
Waiting for the cluster to join...
>>> Performing Cluster Check (using node 192.168.1.198:7000)
M: 2f70e9f2b4a06a846e46d7034a54e0fe6971beea 192.168.1.198:7000
   slots:5461-10922 (5462 slots) master
M: e60f49920cf8620927b200b0001892d08067d065 192.168.1.198:7001
   slots: (0 slots) master
   replicates 02f1958bd5032caca2fd47a56362c8d562d7e621
M: 26101db06b5c2d4431ca8308cf43d51f6939b4fc 192.168.1.198:7002
   slots: (0 slots) master
   replicates 6c4f18b9e8729c3ab5d43b00b0bc1e2ee976f299
M: 02f1958bd5032caca2fd47a56362c8d562d7e621 192.168.1.199:7003
   slots:0-5460 (5461 slots) master
M: 6c4f18b9e8729c3ab5d43b00b0bc1e2ee976f299 192.168.1.199:7004
   slots:10923-16383 (5461 slots) master
M: ebb27bd0a48b67a4f4e0584be27c1c909944e935 192.168.1.199:7005
   slots: (0 slots) master
   replicates 2f70e9f2b4a06a846e46d7034a54e0fe6971beea
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.

create命令可选replicas参数，replicas表示需要有几个slave。最简单命令使用如下：

$ruby redis-trib.rb create 10.180.157.199:6379 10.180.157.200:6379 10.180.157.201:6379
有一个slave的创建命令如下：

$ruby redis-trib.rb create --replicas 1 10.180.157.199:6379 10.180.157.200:6379 10.180.157.201:6379 10.180.157.202:6379  10.180.157.205:6379  10.180.157.208:6379
创建流程如下：

1、首先为每个节点创建ClusterNode对象，包括连接每个节点。检查每个节点是否为独立且db为空的节点。执行load_info方法导入节点信息。
2、检查传入的master节点数量是否大于等于3个。只有大于3个节点才能组成集群。
3、计算每个master需要分配的slot数量，以及给master分配slave。分配的算法大致如下：
先把节点按照host分类，这样保证master节点能分配到更多的主机中。
不停遍历遍历host列表，从每个host列表中弹出一个节点，放入interleaved数组。直到所有的节点都弹出为止。
master节点列表就是interleaved前面的master数量的节点列表。保存在masters数组。
计算每个master节点负责的slot数量，保存在slots_per_node对象，用slot总数除以master数量取整即可。
遍历masters数组，每个master分配slots_per_node个slot，最后一个master，分配到16384个slot为止。
接下来为master分配slave，分配算法会尽量保证master和slave节点不在同一台主机上。对于分配完指定slave数量的节点，还有多余的节点，也会为这些节点寻找master。分配算法会遍历两次masters数组。
第一次遍历masters数组，在余下的节点列表找到replicas数量个slave。每个slave为第一个和master节点host不一样的节点，如果没有不一样的节点，则直接取出余下列表的第一个节点。
第二次遍历是在对于节点数除以replicas不为整数，则会多余一部分节点。遍历的方式跟第一次一样，只是第一次会一次性给master分配replicas数量个slave，而第二次遍历只分配一个，直到余下的节点被全部分配出去。
4、打印出分配信息，并提示用户输入“yes”确认是否按照打印出来的分配方式创建集群。
5、输入“yes”后，会执行flush_nodes_config操作，该操作执行前面的分配结果，给master分配slot，让slave复制master，对于还没有握手（cluster meet）的节点，slave复制操作无法完成，不过没关系，flush_nodes_config操作出现异常会很快返回，后续握手后会再次执行flush_nodes_config。
6、给每个节点分配epoch，遍历节点，每个节点分配的epoch比之前节点大1。
7、节点间开始相互握手，握手的方式为节点列表的其他节点跟第一个节点握手。
8、然后每隔1秒检查一次各个节点是否已经消息同步完成，使用ClusterNode的get_config_signature方法，检查的算法为获取每个节点cluster nodes信息，排序每个节点，组装成node_id1:slots|node_id2:slot2|...的字符串。如果每个节点获得字符串都相同，即认为握手成功。
9、此后会再执行一次flush_nodes_config，这次主要是为了完成slave复制操作。
10、最后再执行check_cluster，全面检查一次集群状态。包括和前面握手时检查一样的方式再检查一遍。确认没有迁移的节点。确认所有的slot都被分配出去了。
11、至此完成了整个创建流程，返回[OK] All 16384 slots covered.。

如果不用redis-trib.rb，可以使用下面的方式：
可以通过客户端连接该节点，通过命令CLUSTER NODES来查看：

127.0.0.1:6379> CLUSTER NODES
29978c0169ecc0a9054de7f4142155c1ab70258b :6379 myself,master - 0 0 0 connected

2.2 节点握手
节点握手是指一批运行在集群模式的节点通过Gossip协议彼此通信，达到感知对方的过程。节点握手是集群彼此通信的第一步，由客户端发起命令：cluster meet <ip> <port>

127.0.0.1:6379> CLUSTER MEET 127.0.0.1 6380
OK
// 发送CLUSTER NODES可以查看到已经感知到 6380 端口的节点了。
127.0.0.1:6379> CLUSTER NODES
29978c0169ecc0a9054de7f4142155c1ab70258b 127.0.0.1:6379 myself,master - 0 0 1 connected
8f285670923d4f1c599ecc93367c95a30fb8bf34 127.0.0.1:6380 master - 0 1496129041442 0 connected
让所有的节点都互相感知：

127.0.0.1:6379> CLUSTER MEET 127.0.0.1 6381
OK
127.0.0.1:6379> CLUSTER MEET 127.0.0.1 6382
OK
127.0.0.1:6379> CLUSTER MEET 127.0.0.1 6383
OK
127.0.0.1:6379> CLUSTER MEET 127.0.0.1 6384
OK
// 已经全部感知到所有的节点
127.0.0.1:6379> CLUSTER NODES
e0c7961a1b07ab655bc31d8dfd583da565ec167d 127.0.0.1:6384 master - 0 1496129143703 0 connected
961097d6be64ebd2fd739ff719e97565a8cee7b5 127.0.0.1:6382 master - 0 1496129141678 0 connected
29978c0169ecc0a9054de7f4142155c1ab70258b 127.0.0.1:6379 myself,master - 0 0 1 connected
8f285670923d4f1c599ecc93367c95a30fb8bf34 127.0.0.1:6380 master - 0 1496129142682 3 connected
6fb7dfdb6188a9fe53c48ea32d541724f36434e9 127.0.0.1:6383 master - 0 1496129145699 4 connected
66478bda726ae6ba4e8fb55034d8e5e5804223ff 127.0.0.1:6381 master - 0 1496129147704 2 connected
当前已经使这六个节点组成集群，但是现在还无法工作，因为集群节点还没有分配槽（slot）。

2.3 分配槽
可以看一下6379端口的槽个数

127.0.0.1:6379> CLUSTER INFO
cluster_state:fail
cluster_slots_assigned:0            // 被分配槽的个数为0
cluster_slots_ok:0
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:6
cluster_size:0
cluster_current_epoch:5
cluster_my_epoch:1
cluster_stats_messages_sent:479
cluster_stats_messages_received:479
接下来为节点分配槽空间。通过cluster addslots命令。

redis-cli -h 127.0.0.1 -p 6379 cluster addslots {0..5461}
OK
redis-cli -h 127.0.0.1 -p 6380 cluster addslots {5462..10922}
OK
redis-cli -h 127.0.0.1 -p 6381 cluster addslots {10923..16383}
OK
我们将16383个槽平均分配给6379、6380、6381端口的节点。再次执行CLUSTER INFO查看一下集群的状态：

127.0.0.1:6379> CLUSTER INFO
cluster_state:ok                // 集群状态OK
cluster_slots_assigned:16384    // 已经分配了所有的槽
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:6
cluster_size:3
cluster_current_epoch:5
cluster_my_epoch:1
cluster_stats_messages_sent:1212
cluster_stats_messages_received:1212
可以通过CLUSTER NODES来查看分配情况：

127.0.0.1:6379> CLUSTER NODES
e0c7961a1b07ab655bc31d8dfd583da565ec167d 127.0.0.1:6384 master - 0 1496129666347 0 connected
961097d6be64ebd2fd739ff719e97565a8cee7b5 127.0.0.1:6382 master - 0 1496129664844 5 connected
29978c0169ecc0a9054de7f4142155c1ab70258b 127.0.0.1:6379 myself,master - 0 0 1 connected 0-5461
8f285670923d4f1c599ecc93367c95a30fb8bf34 127.0.0.1:6380 master - 0 1496129665846 3 connected 5462-10922
6fb7dfdb6188a9fe53c48ea32d541724f36434e9 127.0.0.1:6383 master - 0 1496129661838 4 connected
66478bda726ae6ba4e8fb55034d8e5e5804223ff 127.0.0.1:6381 master - 0 1496129666848 2 connected 10923-16383
目前还有三个节点没有使用，作为一个完整的集群，每个负责处理槽的节点应该具有从节点，保证当主节点出现故障时，可以自动进行故障转移。集群模式下，首次启动的节点和被分配槽的节点都是主节点，从节点负责复制主节点槽的信息和相关数据。
使用cluster replicate <nodeid>在从节点上执行。

redis-cli -h 127.0.0.1 -p 6382 cluster replicate 29978c0169ecc0a9054de7f4142155c1ab70258b
OK
redis-cli -h 127.0.0.1 -p 6383 cluster replicate 8f285670923d4f1c599ecc93367c95a30fb8bf34
OK
redis-cli -h 127.0.0.1 -p 6384 cluster replicate 66478bda726ae6ba4e8fb55034d8e5e5804223ff
OK
通过CLUSTER NODES可以查看集群节点的状态

127.0.0.1:6379> CLUSTER NODES
e0c7961a1b07ab655bc31d8dfd583da565ec167d 127.0.0.1:6384 slave 66478bda726ae6ba4e8fb55034d8e5e5804223ff 0 1496130082754 2 connected
961097d6be64ebd2fd739ff719e97565a8cee7b5 127.0.0.1:6382 slave 29978c0169ecc0a9054de7f4142155c1ab70258b 0 1496130080749 5 connected
29978c0169ecc0a9054de7f4142155c1ab70258b 127.0.0.1:6379 myself,master - 0 0 1 connected 0-5461
8f285670923d4f1c599ecc93367c95a30fb8bf34 127.0.0.1:6380 master - 0 1496130078744 3 connected 5462-10922
6fb7dfdb6188a9fe53c48ea32d541724f36434e9 127.0.0.1:6383 slave 8f285670923d4f1c599ecc93367c95a30fb8bf34 0 1496130079747 4 connected
66478bda726ae6ba4e8fb55034d8e5e5804223ff 127.0.0.1:6381 master - 0 1496130081751 2 connected 10923-16383


7、测试集群
server1上登录redis客户端并执行
[python] view plain copy 在CODE上查看代码片派生到我的代码片
[root@localhost src]# ./redis-cli -c -p 7001
127.0.0.1:7000> get key
-> Redirected to slot [12539] located at 192.168.1.199:7004
"val"
192.168.1.199:7004> set name test
-> Redirected to slot [5798] located at 192.168.1.198:7000
OK
192.168.1.198:7000> set adress shanghai
-> Redirected to slot [1562] located at 192.168.1.199:7003
OK
192.168.1.199:7003>
server2上登录redis客户端并执行
[python] view plain copy 在CODE上查看代码片派生到我的代码片
[root@localhost src]# redis-cli -c -p 7003
127.0.0.1:7003> set key val
-> Redirected to slot [12539] located at 192.168.1.199:7004
OK
192.168.1.199:7004> get keyv
"val"
192.168.1.199:7004> set key2 val2
-> Redirected to slot [4998] located at 192.168.1.199:7003
OK
192.168.1.199:7003> get key2
"val2"
192.168.1.199:7003>


从中可以发现存时是分布式存储，取时也是从集群中取，测试成功

Redis3重建Cluster

1、关闭cluster全部节点
2、删除所有nodes.conf文件
3、开启全部节点
4、依次flushall
5、重建集群即可

nohup  ./src/redis-server /web/redis/7001/redis.conf &