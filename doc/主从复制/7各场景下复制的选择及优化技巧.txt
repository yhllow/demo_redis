第一次建立复制
	此时全量复制不可避免，但仍有几点需要注意：如果主节点的数据量较大，应该尽量避开流量的高峰期，避免造成阻塞。
	如果有多个从节点需要建立对主节点的复制，可以考虑将几个从节点错开，避免主节点带宽占用过大。
	此外，如果从节点过多，也可以调整主从复制的拓扑结构，由一主多从结构变为树状结构（中间的节点既是其主节点的从节点，也是其从节点的主节点）。
	但使用树状结构应该谨慎：虽然主节点的直接从节点减少，降低了主节点的负担，但是多层从节点的延迟增大，数据一致性变差；且结构复杂，维护相当困难。

主节点重启
	主节点重启可以分为两种情况来讨论，一种是故障导致宕机，另一种则是有计划的重启。
	主节点宕机：主节点宕机重启后，runid 会发生变化，因此不能进行部分复制，只能全量复制。
	实际上在主节点宕机的情况下，应进行故障转移处理，将其中的一个从节点升级为主节点，其他从节点从新的主节点进行复制；且故障转移应尽量的自动化，后面文章将要介绍的哨兵便可以进行自动的故障转移。
	安全重启 debug reload：在一些场景下，可能希望对主节点进行重启，例如主节点内存碎片率过高，或者希望调整一些只能在启动时调整的参数。
		如果使用普通的手段重启主节点，会使得 runid 发生变化，可能导致不必要的全量复制。
		为了解决这个问题，Redis 提供了 debug reload 的重启方式：重启后，主节点的 runid 和 offset 都不受影响，避免了全量复制。
		如下图所示，debug reload 重启后 runid 和 offset 都未受影响。
		但 debug reload 是一柄双刃剑：它会清空当前内存中的数据，重新从 RDB 文件中加载，这个过程会导致主节点的阻塞，因此也需要谨慎。

从节点重启
	从节点宕机重启后，其保存的主节点的 runid 会丢失，因此即使再次执行 slaveof，也无法进行部分复制。

网络中断
	如果主从节点之间出现网络问题，造成短时间内网络中断，可以分为多种情况讨论。
	第一种情况：网络问题时间极为短暂，只造成了短暂的丢包，主从节点都没有判定超时（未触发 repl-timeout）；此时只需要通过 REPLCONF ACK 来补充丢失的数据即可。
	第二种情况：网络问题时间很长，主从节点判断超时（触发了 repl-timeout），且丢失的数据过多，超过了复制积压缓冲区所能存储的范围；此时主从节点无法进行部分复制，只能进行全量复制。
		为了尽可能避免这种情况的发生，应该根据实际情况适当调整复制积压缓冲区的大小；此外及时发现并修复网络中断，也可以减少全量复制。
	第三种情况：介于前述两种情况之间，主从节点判断超时，且丢失的数据仍然都在复制积压缓冲区中；此时主从节点可以进行部分复制。